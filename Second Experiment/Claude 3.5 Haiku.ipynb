{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6e62d00-0313-4205-a947-006d6d93624b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Task**\n",
    "--------\n",
    "\n",
    "Create a Databricks python code that extracts air quality data from an API, groups it by month, and calculates monthly averages for all pollutant measurements.\n",
    "\n",
    "**Requirements**\n",
    "----------------\n",
    "\n",
    "### **1\\. Extract Data**\n",
    "\n",
    "*   Fetch air quality data from: https://air-quality-api.open-meteo.com/v1/air-quality?latitude=40.3548&longitude=18.1724&hourly=pm10,pm2\\_5,carbon\\_monoxide,carbon\\_dioxide,nitrogen\\_dioxide,sulphur\\_dioxide,ozone&start\\_date=2025-03-01&end\\_date=2025-08-31\n",
    "    \n",
    "*   Use Python requests to get the JSON response\n",
    "    \n",
    "\n",
    "### **2\\. Transform Data**\n",
    "\n",
    "*   Parse the JSON hourly data into a PySpark DataFrame\n",
    "    \n",
    "*   Convert time and pollutant lists into structured rows\n",
    "    \n",
    "*   Extract year and month from timestamp for grouping\n",
    "    \n",
    "*   Add an ingestion\\_date column\n",
    "    \n",
    "\n",
    "### **3\\. Monthly Aggregation**\n",
    "\n",
    "*   Group data by year and month\n",
    "    \n",
    "*   Calculate average values for each pollutant (pm10, pm2\\_5, carbon\\_monoxide, etc.)\n",
    "    \n",
    "*   Handle null values appropriately during aggregation\n",
    "    \n",
    "*   Create a summary DataFrame with monthly averages\n",
    "    \n",
    "\n",
    "### **4\\. Save Results**\n",
    "\n",
    "*   Save the monthly aggregated data to Delta table air\\_quality\\_monthly\\_avg (append mode)\n",
    "    \n",
    "*   Include progress updates and execution times\n",
    "    \n",
    "*   Display sample results and summary statistics\n",
    "    \n",
    "\n",
    "**Output**\n",
    "----------\n",
    "\n",
    "A complete Databricks python code that performs monthly aggregation of air quality data with proper error handling and result visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45725e9a-b967-4c35-95a0-551539daf5b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Notebook: Air Quality Monthly Aggregation\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, year, month, current_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"AirQualityMonthlyAggregation\").getOrCreate()\n",
    "\n",
    "def fetch_air_quality_data():\n",
    "    \"\"\"\n",
    "    Fetch air quality data from the Open Meteo API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://air-quality-api.open-meteo.com/v1/air-quality\"\n",
    "        params = {\n",
    "            \"latitude\": 40.3548,\n",
    "            \"longitude\": 18.1724,\n",
    "            \"hourly\": \"pm10,pm2_5,carbon_monoxide,carbon_dioxide,nitrogen_dioxide,sulphur_dioxide,ozone\",\n",
    "            \"start_date\": \"2025-03-01\",\n",
    "            \"end_date\": \"2025-08-31\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad responses\n",
    "        \n",
    "        # Print raw response for debugging\n",
    "        print(\"Raw API Response:\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "def transform_air_quality_data(air_quality_json):\n",
    "    \"\"\"\n",
    "    Transform JSON data into a structured PySpark DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input JSON structure\n",
    "        if not air_quality_json or 'hourly' not in air_quality_json:\n",
    "            raise ValueError(\"Invalid JSON structure\")\n",
    "        \n",
    "        # Check if all required keys exist\n",
    "        required_keys = ['time', 'pm10', 'pm2_5', 'carbon_monoxide', \n",
    "                         'carbon_dioxide', 'nitrogen_dioxide', \n",
    "                         'sulphur_dioxide', 'ozone']\n",
    "        \n",
    "        for key in required_keys:\n",
    "            if key not in air_quality_json['hourly']:\n",
    "                raise ValueError(f\"Missing key in hourly data: {key}\")\n",
    "        \n",
    "        # Define schema for the DataFrame\n",
    "        schema = StructType([\n",
    "            StructField(\"timestamp\", TimestampType(), True),\n",
    "            StructField(\"pm10\", DoubleType(), True),\n",
    "            StructField(\"pm2_5\", DoubleType(), True),\n",
    "            StructField(\"carbon_monoxide\", DoubleType(), True),\n",
    "            StructField(\"carbon_dioxide\", DoubleType(), True),\n",
    "            StructField(\"nitrogen_dioxide\", DoubleType(), True),\n",
    "            StructField(\"sulphur_dioxide\", DoubleType(), True),\n",
    "            StructField(\"ozone\", DoubleType(), True),\n",
    "            StructField(\"ingestion_date\", TimestampType(), True)\n",
    "        ])\n",
    "        \n",
    "        # Prepare data for DataFrame\n",
    "        data = []\n",
    "        timestamps = air_quality_json['hourly']['time']\n",
    "        pollutants = {\n",
    "            'pm10': air_quality_json['hourly']['pm10'],\n",
    "            'pm2_5': air_quality_json['hourly']['pm2_5'],\n",
    "            'carbon_monoxide': air_quality_json['hourly']['carbon_monoxide'],\n",
    "            'carbon_dioxide': air_quality_json['hourly']['carbon_dioxide'],\n",
    "            'nitrogen_dioxide': air_quality_json['hourly']['nitrogen_dioxide'],\n",
    "            'sulphur_dioxide': air_quality_json['hourly']['sulphur_dioxide'],\n",
    "            'ozone': air_quality_json['hourly']['ozone']\n",
    "        }\n",
    "        \n",
    "        # Print data lengths for debugging\n",
    "        print(\"Data Lengths:\")\n",
    "        for key, value in pollutants.items():\n",
    "            print(f\"{key}: {len(value)}\")\n",
    "        print(f\"Timestamps: {len(timestamps)}\")\n",
    "        \n",
    "        ingestion_date = datetime.now()\n",
    "        \n",
    "        for i in range(len(timestamps)):\n",
    "            row = [\n",
    "                datetime.fromisoformat(timestamps[i]),\n",
    "                pollutants['pm10'][i] if pollutants['pm10'][i] is not None else None,\n",
    "                pollutants['pm2_5'][i] if pollutants['pm2_5'][i] is not None else None,\n",
    "                pollutants['carbon_monoxide'][i] if pollutants['carbon_monoxide'][i] is not None else None,\n",
    "                pollutants['carbon_dioxide'][i] if pollutants['carbon_dioxide'][i] is not None else None,\n",
    "                pollutants['nitrogen_dioxide'][i] if pollutants['nitrogen_dioxide'][i] is not None else None,\n",
    "                pollutants['sulphur_dioxide'][i] if pollutants['sulphur_dioxide'][i] is not None else None,\n",
    "                pollutants['ozone'][i] if pollutants['ozone'][i] is not None else None,\n",
    "                ingestion_date\n",
    "            ]\n",
    "            data.append(row)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = spark.createDataFrame(data, schema)\n",
    "        \n",
    "        # Print DataFrame info\n",
    "        print(\"DataFrame Info:\")\n",
    "        df.printSchema()\n",
    "        df.show(5)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Detailed Error in transform_air_quality_data: {e}\")\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "def aggregate_monthly_data(df):\n",
    "    \"\"\"\n",
    "    Group and aggregate data by month\n",
    "    \"\"\"\n",
    "    try:\n",
    "        monthly_avg = df.groupBy(\n",
    "            year(col(\"timestamp\")).alias(\"year\"),\n",
    "            month(col(\"timestamp\")).alias(\"month\")\n",
    "        ).agg(\n",
    "            avg(\"pm10\").alias(\"avg_pm10\"),\n",
    "            avg(\"pm2_5\").alias(\"avg_pm2_5\"),\n",
    "            avg(\"carbon_monoxide\").alias(\"avg_carbon_monoxide\"),\n",
    "            avg(\"carbon_dioxide\").alias(\"avg_carbon_dioxide\"),\n",
    "            avg(\"nitrogen_dioxide\").alias(\"avg_nitrogen_dioxide\"),\n",
    "            avg(\"sulphur_dioxide\").alias(\"avg_sulphur_dioxide\"),\n",
    "            avg(\"ozone\").alias(\"avg_ozone\")\n",
    "        )\n",
    "        \n",
    "        return monthly_avg\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error aggregating data: {e}\")\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Fetch air quality data\n",
    "        air_quality_json = fetch_air_quality_data()\n",
    "        if not air_quality_json:\n",
    "            raise ValueError(\"Failed to fetch air quality data\")\n",
    "        \n",
    "        # Transform data to DataFrame\n",
    "        air_quality_df = transform_air_quality_data(air_quality_json)\n",
    "        if air_quality_df is None:\n",
    "            raise ValueError(\"Failed to transform air quality data\")\n",
    "        \n",
    "        # Aggregate monthly data\n",
    "        monthly_avg_df = aggregate_monthly_data(air_quality_df)\n",
    "        if monthly_avg_df is None:\n",
    "            raise ValueError(\"Failed to aggregate monthly data\")\n",
    "        \n",
    "        # Save to Delta table\n",
    "        monthly_avg_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"air_quality_monthly_avg\")\n",
    "        \n",
    "        # Display results\n",
    "        monthly_avg_df.show()\n",
    "        monthly_avg_df.printSchema()\n",
    "        \n",
    "        # Execution summary\n",
    "        end_time = datetime.now()\n",
    "        print(f\"Execution completed in {end_time - start_time}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e00388c7-8c21-479f-a349-1dc70f2ab389",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Claude Haiku 3.5 need 1 fix to work"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Claude 3.5 Haiku",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
